{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing whether missing file or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# All files ending with .txt\n",
    "mypath = \"./craw_data/2020-02-01/\"\n",
    "\n",
    "onlyfiles_set = set([f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))])\n",
    "print(f'total file: {len(onlyfiles_set)}')\n",
    "\n",
    "base_dir = './craw_data'\n",
    "list_date = os.listdir(base_dir)\n",
    "for date in list_date:\n",
    "\tdate_folder = os.path.join(base_dir, date)\n",
    "\tdate_file_set = set([f for f in os.listdir(date_folder) if (os.path.isfile(os.path.join(date_folder, f)))])\n",
    "\tmissing = onlyfiles_set - date_file_set\n",
    "\tif missing:\n",
    "\t\tprint(f'date: {date}, missing: {missing}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating and combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(date_text):\n",
    "\tconvert_date = \"\"\n",
    "\ttry:\n",
    "\t\tdate = datetime.datetime.strptime(date_text, '%d %b %Y')\n",
    "\t\tconvert_date = datetime.datetime.strftime(date, '%Y-%m-%d')\n",
    "\texcept:\n",
    "\t\tconvert_date = None\n",
    "\treturn convert_date\n",
    "\n",
    "# tmp = validate('1 Feb 2021')\n",
    "# print(tmp)\n",
    "# print(validate('Time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_numpy(file_name):\n",
    "\tparent_folder = Path(file_name)\n",
    "\tdate = os.path.basename(parent_folder.parent.absolute())\n",
    "\tdate = date.split('-')[0]\n",
    "\n",
    "\tsiteId = os.path.basename(file_name)\n",
    "\tsiteId = siteId.split('.')[0]\n",
    "\n",
    "\tfile_pd = pd.read_csv(file_name)\n",
    "\tfile_pd = file_pd[file_pd['Time'] == '00-24']\n",
    "\tcolumns_name = file_pd.columns \n",
    "\tnew_column_names = {}\n",
    "\tfor name in columns_name:\n",
    "\t\ttmp = f'{name} {date}'\n",
    "\t\tif validate(tmp):\n",
    "\t\t\tnew_column_names[name] = validate(tmp)\n",
    "\n",
    "\t# select only date column \n",
    "\tfile_pd = file_pd[list(new_column_names.keys())]\n",
    "\tfile_pd.rename(columns = new_column_names, inplace=True)\n",
    "\n",
    "\t# convert to format: date, traffict_count\n",
    "\tfile_pd = file_pd.transpose()\n",
    "\tfile_pd.columns = ['traffic_count']\n",
    "\tfile_pd['site_id'] = siteId\n",
    "\n",
    "\treturn file_pd.reset_index().to_numpy()\n",
    "\n",
    "\n",
    "# file_name = os.path.join(date_folder, \"1011.csv\")\n",
    "# print(file_name)\n",
    "# tmp_pd = convert_csv_to_numpy(file_name)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"./combine_data\"\n",
    "def combine_date_folder_into_one(date_folder):\n",
    "\tlist_files = os.listdir(date_folder)\n",
    "\tcombine_numpy = np.empty((0, 3))\n",
    "\tfor file_name in list_files:\n",
    "\t\t\tcombine_numpy = np.concatenate((combine_numpy, convert_csv_to_numpy(os.path.join(date_folder, file_name))))\n",
    "\t\n",
    "\tdate = os.path.basename(date_folder)\n",
    "\tcombine_df = pd.DataFrame(combine_numpy,columns=['Time', 'traffic_count', 'siteId'])\n",
    "\n",
    "\tif not os.path.exists(save_folder):\n",
    "\t\tos.makedirs(save_folder)\n",
    "\n",
    "\tcombine_df.to_csv(os.path.join(save_folder, date), index=False)\n",
    "\tprint(f'done date: {date}')\n",
    "\n",
    "\n",
    "# combine_date_folder_into_one(date_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "craw_folder = \"./craw_data\"\n",
    "def combine_craw_data_folder():\n",
    "\tlist_date_folder = os.listdir(craw_folder)\n",
    "\tlist_date_folder.sort()\n",
    "\tfor date_folder in list_date_folder:\n",
    "\t\tcombine_date_folder_into_one(os.path.join(craw_folder, date_folder))\n",
    "\n",
    "# combine_craw_data_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_to_single_file():\n",
    "\tli = []\n",
    "\tall_files = os.listdir(save_folder)\n",
    "\tfor filename in all_files:\n",
    "\t\tfilename = os.path.join(save_folder, filename)\n",
    "\t\tdf = pd.read_csv(filename, index_col=None, header=0)\n",
    "\t\tli.append(df)\n",
    "\n",
    "\tframe = pd.concat(li, axis=0, ignore_index=True)\n",
    "\tframe.to_csv(os.path.join(save_folder, \"traffic_count_all.csv\"), index=False)\n",
    "\n",
    "# combine_to_single_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by week with avg traffic count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by week \n",
    "file_name = '/home/minhnhat/data/combine_data/traffic_count_all.csv'\n",
    "def group_by_week(file_name):\n",
    "\tdf = pd.read_csv(file_name)\n",
    "\t# some traffic_count is -, it means can't craw or some errors happen\n",
    "\tdf['traffic_count'] = pd.to_numeric(df['traffic_count'], errors ='coerce').fillna(0).astype('int') \n",
    "\tdf['Time'] = pd.to_datetime(df['Time'])\n",
    "\tgroup_by_week_df = df.groupby(['siteId', pd.Grouper(key='Time', freq='W-MON')])['traffic_count'].mean().reset_index()\n",
    "\tgroup_by_week_df.to_csv(os.path.join(save_folder, \"traffic_count_group_by_week.csv\"), index=False)\n",
    "\n",
    "\t\n",
    "group_by_week(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_week_file_name = './combine_data/traffic_count_group_by_week.csv'\n",
    "test = pd.read_csv(group_by_week_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siteId           0\n",
       "Time             0\n",
       "traffic_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteId</th>\n",
       "      <th>Time</th>\n",
       "      <th>traffic_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1011</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>53425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>54979.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>56062.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>56570.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>57157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   siteId        Time  traffic_count\n",
       "0    1011  2020-02-03   53425.000000\n",
       "1    1011  2020-02-10   54979.428571\n",
       "2    1011  2020-02-17   56062.857143\n",
       "3    1011  2020-02-24   56570.428571\n",
       "4    1011  2020-03-02   57157.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219488, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = '/home/minhnhat/data/combine_data/traffic_count_all.csv'\n",
    "\n",
    "tmp = pd.read_csv(file_name)\n",
    "tmp.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81a9705b46ae3331c689bfe61e5aa8d9e050378630fcee24b5eb9e6eb0fbd522"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('analyse-movement': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
